{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc08e11f-70cf-4f62-af15-f86654875f1f",
   "metadata": {},
   "source": [
    "# Hackathon\n",
    "<img src='../images/xebia-logo.png' width='300px' align='right' style=\"padding: 15px\">\n",
    "\n",
    "This notebook provides some scaffolding for the hackathon that marks the end of the *Production-Ready Machine Learning* training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648b158-4c04-49b7-995b-4143856f2442",
   "metadata": {},
   "source": [
    "If you've followed all the steps of the training you should have a working ML aplication that can load data, train ML models on the data and generate predictions for nobel data.\n",
    "\n",
    "In this notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667858a-ced7-476a-92c8-16d7002c4656",
   "metadata": {},
   "source": [
    "### Expose the model as an API and/or CLI.\n",
    "- There should be a `train` endpoint/subcommand that accepts data, calls some internal functions, and saves a new copy of the model.\n",
    "- There should be a `predict` endpoint/subcommand that accepts data, a model name and returns some predictions.\n",
    "    - Think of the format of the response. There are multiple options, some examples in order of complexity include: returning the data as JSON, streaming `.csv` files, streaming Avro chunks.\n",
    "- You should include loggers and tests for your endpoints/subcommands.\n",
    "- You can also expose some metrics calculations and reporting. You might need to change the modeling strategy to include a cross-validation step.\n",
    "- If you are familiar with using containers, you can try containerizing the application and exposing the API in a container port.\n",
    "\n",
    "The following code can act as scaffolding. Ideally, the code that serves your application (i.e. the API or the CLI) should live in a different package that import `animal_shelter`. You can create a `app` or `cli` directory for this at the root of your project with a different script. Ideally even a fully-fledged package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94caa4f8-374b-4f25-bcc9-1a54aed8d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton of an API definition\n",
    "import logging\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI\n",
    "\n",
    "from animal_shelter.data import load_data\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "model = joblib.load(...)\n",
    "\n",
    "@app.post(\"/train/\")\n",
    "def train(data):\n",
    "    # Load/process data\n",
    "    # Pass data to functions from animal_shelter\n",
    "    # Check that the model is saved correctly\n",
    "    # Generate a response with useful information\n",
    "    return response\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "def predict(data):\n",
    "    # Load/process data\n",
    "    # Generate predictions by calling functions from animal_shelter\n",
    "    # Format predictions\n",
    "    # Generate a response with the  predictions\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b651255-b5ee-4170-b748-546e27fb3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton for a CLI\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import typer\n",
    "\n",
    "from animal_shelter.data import load_data\n",
    "\n",
    "app = typer.Typer()\n",
    "\n",
    "# Always gets called before all subcommands\n",
    "@app.callback()\n",
    "def main() -> None:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"[%(asctime)-15s] %(name)s - %(levelname)s - %(message)s\",\n",
    "    )\n",
    "\n",
    "\n",
    "@app.command()\n",
    "def train(input_path: Path, model_path: Path) -> None:\n",
    "    \"\"\"Trains a model on the given dataset.\"\"\"\n",
    "    typer.echo(f\"Loading {input_path}\")\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"Loading input dataset from %s\", input_path)\n",
    "    \n",
    "    # Load/process data\n",
    "    # Pass data to functions from animal_shelter\n",
    "    # Check that the model is saved correctly\n",
    "    # Output some useful feedback for the user\n",
    "    \n",
    "@app.command()\n",
    "def predict(input_path: Path, model_path: Path, output_path: Path) -> None:\n",
    "    \"\"\"Applies a model to the given dataset.\"\"\"\n",
    "    typer.echo(f\"Loading {input_path}\")\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    # Load/process data\n",
    "    # Generate predictions by calling functions from animal_shelter\n",
    "    # Format predictions\n",
    "    # Save/return predictions and some useful feedback for the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc28a2-0b95-4888-bbfa-71c181993761",
   "metadata": {},
   "source": [
    "### More tests!\n",
    "- Implement some test that call a function multiple times, but each time using a randomly generated input.\n",
    "- Some end-to-end tests that test the functionality of your full pipeline including loading data, training a model, generating predictions and serving them.\n",
    "  - With mocked data.\n",
    "  - With a subset of the training data.\n",
    "- Some tests that check that the performance of a model doesn't fall from a pre-specified threshold.\n",
    "  - Check some model performance metrics (e.g. accuracy, recall, precission), but also some computational metrics (e.g. time to run).\n",
    "- Write some tests using Pydantic to check the output of the different steps of your modeling pipelines.\n",
    "\n",
    "**Some general tips:**\n",
    "- Don't forget to set random seeds when your functions run non-deterministic code.\n",
    "- Don't be afraid to break up your functions into smaller ones if it makes writing tests easier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
