{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc08e11f-70cf-4f62-af15-f86654875f1f",
   "metadata": {},
   "source": [
    "# More testing practice...\n",
    "<img src='../images/xebia-logo.png' width='300px' align='right' style=\"padding: 15px\">\n",
    "\n",
    "### ... and high-quality-code-writing practice!\n",
    "\n",
    "Your goal for this section of the training will be to refactor some code produced by a Data Scientist that implements a ML application for the animal shelter usecase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cfc279-8f30-415c-a88f-b2fb77d65f46",
   "metadata": {},
   "source": [
    "A good design principle is that *good* functions are *testable* functions. So try to break down the code at the end of the notebook into the smallest units that you think makes sense testing.\n",
    "\n",
    "Once the code is refactored, you should be able to call the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce0ef6-1528-4a45-8c22-43c55f6c9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animal_shelter.model.train import train\n",
    "from animal_shelter.model.predict import predict\n",
    "\n",
    "train(\"../data/train.csv\", \"../output/model.pkl\")\n",
    "predict(\"../data/test.csv\", \"../output/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9355f-d70c-4439-848e-386a46dea895",
   "metadata": {},
   "source": [
    "1. Create a subpackage called `model` within `animal_shelter`.\n",
    "2. Create two modules called `train` and `predict` within that subpackage.\n",
    "3. Copy-paste the code from bellow into the respective modules, and make sure that all imports are correct.\n",
    "4. Refactor the code into smaller functions, and write unit tests for their essential behaviour.\n",
    "    - Think about which individual steps *make sense testing*.\n",
    "    - Think about which parameter types your functions should accept.\n",
    "    - Here are some pointers:\n",
    "        - You probably want a function called `train` that accepts a `Path` (from `pathlib`) to the training data and another `Path` to a location where to save a fitted model (e.g. `output/model.pkl`).\n",
    "        - You probably want to abstract away the process of building the `Pipeline` into a separate function so that you can test that it's constructed properly.\n",
    "        - You probabl also want a function called `predict` that accepts a `Path` to the data and a `Path` to the model used to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a8b80f-6fbd-4a8c-94c9-7ab108bddfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from animal_shelter.data import load_data\n",
    "from animal_shelter.features import add_features\n",
    "\n",
    "raw_data = load_data(\"../data/train.csv\")\n",
    "with_features = add_features(raw_data)\n",
    "cat_features = [                                  \n",
    "    \"animal_type\",                                        \n",
    "    \"is_dog\",                                             \n",
    "    \"has_name\",                                           \n",
    "    \"sex\",                                                \n",
    "    \"hair_type\",                                          \n",
    "]                                                         \n",
    "num_features = [\"days_upon_outcome\"]                  \n",
    "\n",
    "num_transformer = Pipeline(                                                \n",
    "    steps=[(\"imputer\", SimpleImputer()), (\"scaler\", StandardScaler())]     \n",
    ")                                                                          \n",
    "cat_transformer = Pipeline(steps=[(\"onehot\", OneHotEncoder(drop=\"first\"))])\n",
    "transformer = ColumnTransformer(                                           \n",
    "    (                                                                      \n",
    "        (\"numeric\", num_transformer, num_features),                        \n",
    "        (\"categorical\", cat_transformer, cat_features),                    \n",
    "    )                                                                      \n",
    ")\n",
    "\n",
    "clf_model = Pipeline(                                                      \n",
    "    [(\"transformer\", transformer), (\"model\", RandomForestClassifier())]    \n",
    ")\n",
    "                                                          \n",
    "X = with_features[cat_features + num_features]\n",
    "y = with_features[\"outcome_type\"] \n",
    "\n",
    "clf_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bc235-74b2-4d46-a024-ab40dc9c5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(\"../data/test.csv\")\n",
    "with_features = add_features(test_data)\n",
    "X_test = with_features[cat_features + num_features]\n",
    "clf_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
